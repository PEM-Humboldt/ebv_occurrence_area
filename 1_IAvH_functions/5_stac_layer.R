### función stac_layer

# Cargar librerias
packages_list<-list("magrittr")
invisible({lapply(packages_list, library, character.only = TRUE)})

# Organizar directorios
args <- commandArgs(trailingOnly=TRUE)
outputFolder <- args[1]

# Cargar archivos de entrada
input <- rjson::fromJSON(file=file.path(outputFolder, "input.json"))

folder_name<- tools::file_path_sans_ext(input$folder_workflow)
folder_results<- paste0(dirname(dirname(dirname(outputFolder))), "/", input$folder_workflow)
setwd(folder_results)



# Cargar stac_colections_layers
stac_colections_layers_file<- paste0(input$collection_layers, ".RData")

if(file.exists(folder_results)){ setwd(folder_results); 
  if(file.exists(stac_colections_layers_file)){
    load(stac_colections_layers_file); 
  } else { stop("No se encuentra el archivo dir_stac especificado") 
  } } else{ stop("No se encuentra el folder_workflow especificado") }

if(!exists("stac_colections_layers")){ stop("Error al cargar archivo dir_stac especificado") } 







## Función core área de estudio, y estimación de metricas área de estudio

## Estimar metricas ÃƒÂ¡rea de estudio
stac_layer<- function(dir_polygon= NULL, res= 1000, colections_layers= NULL){
  
  suppressMessages({
    
    
    # organizar data
    vector_polygon <- vect(dir_polygon) %>% as.polygons()
    crs_polygon<- crs(vector_polygon)
    wkt_polygon <- geom(vector_polygon, wkt=TRUE) %>% {  paste0( "MULTIPOLYGON (",paste(gsub("POLYGON ", "", .), collapse=  ", "),")")  }
    
    
    box_polygon<-  st_bbox(vector_polygon)
    
    
    # estimar metricas por colecciÃƒÂ³n
    list_colections<- pblapply(names(colections_layers), function(y) { print(y)
      
      x<- colections_layers[[y]]
      data_layer <- dplyr::filter(metadata, layer %in% y)
      
      # cubo
      v = cube_view(srs = crs_polygon,  extent = list(t0 = gdalcubes::extent(x)$t0, t1 = gdalcubes::extent(x)$t1,
                                                      left = box_polygon[1], right = box_polygon[3],
                                                      top = box_polygon[4], bottom = box_polygon[2]),
                    dx = res, dy = res, dt = "P1Y", aggregation = "first", resampling = "first", keep.asp= F)
      
      cube <- raster_cube(x, v)
      cube_mask<- filter_geom(cube, geom= wkt_polygon, srs = crs_polygon )
      cube_stars <- st_as_stars(cube_mask) %>% rast()
      
      
      collection_rast<- pblapply(cube_stars, function(x) { if(any( is.na(summary(raster(x))) )){NULL}else{x} } ) %>%
        {Filter(function(x) !is.null(x), .)} %>% {setNames(., unlist(sapply(., function(x) names(x))) )}
      
      list_rast<- pblapply(collection_rast, function(x) {
        
        vals_units<- unique(values(x))
        vals<- data.frame(ID= vals_units[,1], layer= y) %>% list(data_layer) %>% join_all() %>% arrange(ID)
        
        # estimar area (probar freqDT - rasterDT)
        areas<- freqDT(raster(x)) %>% mutate(area_ha = freq*(res^2)  / 10000) %>%
          mutate(prop= area_ha / sum(.$area_ha)) %>%
          {list(vals, .)} %>% join_all()
        
        
        list(name= names(x), layer= x, metadata= areas) }
      )
      
    }) %>% setNames(names(colections_layers))
    
  })
}











## Imprimir resultado - Formao json
output <- list("stac_colections_layers_txt" = output_txt, "stac_colections_layers_RData" = output_RData)
jsonData <- rjson::toJSON(output, indent=2)
write(jsonData, file.path(outputFolder,"output.json"))